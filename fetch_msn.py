#!/usr/bin/env python3
import requests
import json
import os
from datetime import datetime
from bs4 import BeautifulSoup

# Mappning stad ‚Üí MSN:s svenska prognos-URL
MSN_URLS = {
    "eskilstuna": "https://www.msn.com/sv-se/vader/prognos/in-Eskilstuna,Sodermanland-County",
    # L√§gg till √∂vriga st√§der h√§r:
    # "stockholm":  "https://www.msn.com/sv-se/vader/prognos/in-Stockholm,Stockholms-l√§n-County",
    # "g√∂teborg":   "https://www.msn.com/sv-se/vader/prognos/in-G√∂teborg,V√§stra-G√∂talands-l√§n-County",
    # "lomma":      "https://www.msn.com/sv-se/vader/prognos/in-Lomma,Sk√•ne-l√§n-County",
    # "malm√∂":      "https://www.msn.com/sv-se/vader/prognos/in-Malm√∂,Sk√•ne-l√§n-County",
    # "ume√•":       "https://www.msn.com/sv-se/vader/prognos/in-Ume√•,V√§sternorrlands-l√§n-County",
}

# Engelska fallback‚ÄêURL om svensk saknas
EN_URL_TEMPLATE = "https://www.msn.com/en-us/weather/{slug}"

# Lista √∂ver orter
cities = list(MSN_URLS.keys())

OUTPUT_FOLDER = "data"
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

def slugify(city):
    """Enkel slugifiering f√∂r engelska fallback-URL."""
    return city.lower().replace("√•", "a").replace("√§", "a").replace("√∂", "o")

def fetch_html(city):
    # F√∂rst: anv√§nd den svenska URL:en om vi har en
    url = MSN_URLS.get(city)
    if url:
        print(f"üå¶Ô∏è H√§mtar svenska MSN-prognos f√∂r {city}: {url}")
        res = requests.get(url)
        if res.status_code == 404:
            print(f"‚ö†Ô∏è 404 p√• svensk URL, f√∂rs√∂ker engelska...")
        else:
            res.raise_for_status()
            return res.text

    # Fallback: engelska versionen
    slug = slugify(city)
    en_url = EN_URL_TEMPLATE.format(slug=slug)
    print(f"üå¶Ô∏è H√§mtar engelska MSN-prognos f√∂r {city}: {en_url}")
    res = requests.get(en_url)
    if res.status_code == 404:
        print(f"‚ùå Ingen giltig MSN-sida f√∂r {city} (404 p√• b√•de SV & EN)")
        return None
    res.raise_for_status()
    return res.text

def parse_and_save(city, html):
    soup = BeautifulSoup(html, "html.parser")
    tag = soup.find("script", {"id": "__NEXT_DATA__"})
    if not tag or not tag.string:
        print(f"‚ö†Ô∏è Ingen __NEXT_DATA__ JSON f√∂r {city}, skippar.")
        return

    data = json.loads(tag.string)
    hourly = (data.get("props", {})
                  .get("pageProps", {})
                  .get("forecasts", {})
                  .get("hourly", []))
    if not hourly:
        print(f"‚ö†Ô∏è Ingen timdata i JSON f√∂r {city}, skippar.")
        return

    out = []
    for h in hourly:
        iso = h.get("dateTime")
        if not iso:
            continue
        dt = datetime.fromisoformat(iso)
        time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
        out.append({
            "time": time_str,
            "temp": h.get("temperature"),
            "desc": h.get("iconPhrase", "").lower()
        })

    path = os.path.join(OUTPUT_FOLDER, f"msn_{city}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(out, f, indent=2, ensure_ascii=False)
    print(f"‚úÖ Sparat: {path} ({len(out)} datapunkter)")

if __name__ == "__main__":
    for city in cities:
        html = fetch_html(city)
        if html:
            parse_and_save(city, html)
